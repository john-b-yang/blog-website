{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Processing Tools\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit Learn Machine Learning Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "# Data Set\n",
    "from mnist import MNIST\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Part 1: Reading in MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('/Users/johnyang/Desktop/')\n",
    "mnist_images, mnist_labels = mndata.load_testing()\n",
    "\n",
    "# Create DataFrame with 784 (28x28 Image) columns and 10000 rows\n",
    "# Column = feature / color of pixel at specific index\n",
    "# Row = One instance of data \n",
    "mnist_df = pd.DataFrame(mnist_images)\n",
    "\n",
    "# Add labels corresponding to images as last column in table\n",
    "mnist_df.insert(loc=0, column='label', value=mnist_labels)\n",
    "\n",
    "# Separate image pixel values and labels\n",
    "# Take first 5000 images b/c ain't nobody got time for 10000 images\n",
    "images = mnist_df.iloc[0:5000, 1:]\n",
    "labels = mnist_df.iloc[0:5000, :1]\n",
    "\n",
    "# Randomly separate data into testing and training batches\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, train_size=0.5, random_state=0)\n",
    "\n",
    "# Cast pandas array types into numpy arrays to make it easier to run computations\n",
    "train_images_array = train_images.as_matrix()\n",
    "test_images_array = test_images.as_matrix()\n",
    "train_labels_array = train_labels.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 10.0\n",
      "Completed batch in 3.3738150596618652 Seconds.\n",
      "Completed batch in 3.284066915512085 Seconds.\n",
      "Completed batch in 3.172995090484619 Seconds.\n",
      "Completed batch in 3.1866250038146973 Seconds.\n",
      "Completed batch in 3.2541251182556152 Seconds.\n",
      "Completed batch in 3.3960750102996826 Seconds.\n",
      "Completed batch in 3.3485047817230225 Seconds.\n",
      "Completed batch in 3.14313006401062 Seconds.\n",
      "Completed batch in 3.157855987548828 Seconds.\n",
      "Completed batch in 3.200269937515259 Seconds.\n"
     ]
    }
   ],
   "source": [
    "test_images_len = test_images.shape[0]\n",
    "predictions = []\n",
    "\n",
    "batch_size = 250\n",
    "batches = test_images_len/batch_size\n",
    "\n",
    "print(\"Number of batches: \" + str(batches))\n",
    "for i in range(int(batches)):\n",
    "    # Time of batch processing speed\n",
    "    tick = time.time()\n",
    "    \n",
    "    # Euclidean Distance Calculation\n",
    "    test_prediction = test_images_array[(i * batch_size):((i+1) * batch_size)]\n",
    "    dot_product = np.dot(test_prediction, train_images_array.T)\n",
    "    \n",
    "    sum_square_test = np.square(test_prediction).sum(axis=1)\n",
    "    sum_square_train = np.square(train_images_array).sum(axis=1)\n",
    "    \n",
    "    distances = np.sqrt(-2 * dot_product + sum_square_train + np.matrix(sum_square_test).T)\n",
    "    \n",
    "    num_distances = distances.shape[0]\n",
    "    \n",
    "    # Batch Predictions\n",
    "    label_predictions = np.zeros(num_distances)\n",
    "    for j in range(num_distances):\n",
    "        k_closest_y = []\n",
    "        \n",
    "        # Labels from points with distance calculated\n",
    "        calculated_labels = train_labels_array[np.argsort(distances[j,:])].flatten()\n",
    "        \n",
    "        # 3 Closest Neighbors\n",
    "        k_closest_y = calculated_labels[:3]\n",
    "        \n",
    "        # Count Unique Neighbors\n",
    "        counted = Counter(k_closest_y)\n",
    "        \n",
    "        label_predictions[j] = counted.most_common(1)[0][0]\n",
    "    \n",
    "    predictions = predictions + list(label_predictions)\n",
    "    \n",
    "    tock = time.time()\n",
    "    \n",
    "    print(\"Completed batch in \" + str(tock - tick) + \" Seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9116\n"
     ]
    }
   ],
   "source": [
    "prediction_array = np.asarray(predictions)\n",
    "\n",
    "correct = 0\n",
    "count = 0\n",
    "for index, row in test_labels.iterrows():\n",
    "    actual_label= int(row['label'])\n",
    "    if (actual_label == prediction_array[count]):\n",
    "        correct += 1\n",
    "    count += 1\n",
    "\n",
    "print(float(correct) / float(count))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ds100]",
   "language": "python",
   "name": "Python [ds100]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
